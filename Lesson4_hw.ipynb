{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a35d0b6e",
   "metadata": {},
   "source": [
    "# Урок 4. CNN Свертки\n",
    "Обучите CNN (самописная) на CIFAR-100.\n",
    "\n",
    "Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50.\n",
    "\n",
    "*Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50 с аугментацией данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00aa48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149dce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe4a8b1009d4e02a58e0d51f340787c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169001437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.CIFAR100(root='data/', train=True, download=True)\n",
    "\n",
    "\n",
    "class MyOwnCifar(torch.utils.data.Dataset):\n",
    "   \n",
    "    def __init__(self, init_dataset, transform=None):\n",
    "        self._base_dataset = init_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self._base_dataset[idx][0]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self._base_dataset[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_actions = transforms.Compose([transforms.Resize(44),\n",
    "                                    transforms.RandomCrop(32, padding=4), \n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "\n",
    "def train_valid_split(Xt):\n",
    "    X_train, X_test = train_test_split(Xt, test_size=0.2, random_state=13)\n",
    "    return X_train, X_test\n",
    "\n",
    "train_dataset, valid_dataset = train_valid_split(dataset)\n",
    "\n",
    "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
    "valid_dataset = MyOwnCifar(valid_dataset, transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=False,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d70a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for img, lbl in train_loader:\n",
    "    print(img.shape)\n",
    "    print(lbl[0])\n",
    "    plt.imshow(img[0].permute(1, 2, 0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc59cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.dp_one = nn.Dropout(0.2)\n",
    "        self.dp_two = nn.Dropout(0.2)\n",
    "        \n",
    "        self.bn_one = torch.nn.BatchNorm2d(3) \n",
    "        self.conv_one = torch.nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.bn_two = torch.nn.BatchNorm2d(16) \n",
    "        self.conv_two = torch.nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.bn_three = torch.nn.BatchNorm2d(32)\n",
    "        self.conv_three = torch.nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn_four = torch.nn.BatchNorm2d(64)\n",
    "        self.fc1 = torch.nn.Linear(1024, 512)\n",
    "        self.fc2 = torch.nn.Linear(512, 256)\n",
    "        self.out = torch.nn.Linear(256, 100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn_one(x)\n",
    "        x = self.conv_one(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.bn_two(x)\n",
    "        x = self.conv_two(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.bn_three(x)\n",
    "        x = self.conv_three(x)\n",
    "        x = F.leaky_relu(x, 0.1)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.bn_four(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dp_one(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp_two(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        return self.out(x)\n",
    "       \n",
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb3aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3e5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(net.to(device), input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf6625",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "net.train()\n",
    "\n",
    "for epoch in range(num_epochs):  \n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
    "        \n",
    "        # выводим статистику о процессе обучения\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            net.eval()\n",
    "            \n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
    "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
    "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "\n",
    "            test_running_right, test_running_total = 0.0, 0.0\n",
    "            for i, data in enumerate(valid_loader):\n",
    "            \n",
    "                test_outputs = net(data[0].to(device))\n",
    "                test_running_total += len(data[1])\n",
    "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
    "            \n",
    "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
    "        \n",
    "        net.train()\n",
    "        \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc70949",
   "metadata": {},
   "source": [
    "Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "print(resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32140052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(resnet50.to(device), input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in list(resnet50.parameters())[:]:\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e604e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resnet50.fc = nn.Linear(2048, 100)\n",
    "\n",
    "summary(resnet50.to(device), input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d886878",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2724dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_actions = transforms.Compose([\n",
    "                                    # transforms.Resize(40),\n",
    "                                    # transforms.RandomCrop(32, padding=2), \n",
    "                                   transforms.Resize(256),\n",
    "                                   transforms.RandomCrop(224, padding=4), \n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                         std=[0.229, 0.224, 0.225]),\n",
    "                                    ])\n",
    "valid_transforms = transforms.Compose([\n",
    "                                      transforms.Resize(224),\n",
    "                                      #  transforms.Resize(32),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                            std=[0.229, 0.224, 0.225]),\n",
    "                                       ])\n",
    "\n",
    "\n",
    "train_dataset, valid_dataset = train_valid_split(dataset)\n",
    "\n",
    "train_dataset = MyOwnCifar(train_dataset, train_actions)\n",
    "valid_dataset = MyOwnCifar(valid_dataset, valid_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fec0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7e1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "for name, param in resnet50.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "resnet50.train()\n",
    "\n",
    "for epoch in range(num_epochs):  \n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
    "        \n",
    "        # выводим статистику о процессе обучения\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            resnet50.eval()\n",
    "            \n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
    "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
    "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "\n",
    "            test_running_right, test_running_total = 0.0, 0.0\n",
    "            for i, data in enumerate(valid_loader):\n",
    "            \n",
    "                test_outputs = resnet50(data[0].to(device))\n",
    "                test_running_total += len(data[1])\n",
    "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
    "            \n",
    "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
    "\n",
    "        resnet50.train()\n",
    "        \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e9d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
